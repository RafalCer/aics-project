{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARGUMENTS\n",
    "\n",
    "# main_path = 'C:\\Users\\Rafa\\Downloads\\'\n",
    "# path_to_images = '/home/guscerra@GU.GU.SE/aics-project/celeb_images/CelebA-HQ-img/'\n",
    "# captions_dir = r\"C:\\Users\\Rafa\\Downloads\\text\\celeba-caption\"\n",
    "\n",
    "dataset = 'celeb_small_res'\n",
    "main_path = '/Users/evelsve/repos/cap'\n",
    "path_to_images = main_path + f'/data/{dataset}'\n",
    "captions_dir = f'/Users/evelsve/repos/cap/data/captions'\n",
    "\n",
    "\n",
    "predictions_file = \"predictions_m5_sketches.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the longest captions for all images\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def parse_captions(images_dir=None, nr_images):\n",
    "    df = pd.DataFrame(columns=['Img_name', 'Caption', 'Img_path'])\n",
    "    \n",
    "    if images_dir:\n",
    "        os.chdir(images_dir)\n",
    "    else:\n",
    "        os.chdir(r'C:\\Users\\Rafa\\Downloads\\text\\celeba-caption')\n",
    "\n",
    "    files = os.listdir()\n",
    "\n",
    "    for i, file in enumerate(files):\n",
    "        if i > nr_images:\n",
    "            return df\n",
    "        else:\n",
    "            with open(file, 'r') as infile:\n",
    "                descriptions = infile.readlines()\n",
    "\n",
    "                longest = descriptions[0].strip()\n",
    "                for description in descriptions:\n",
    "                    if len(description.strip()) > len(longest):\n",
    "                        longest = description.strip().replace(r'\\n', '')\n",
    "                \n",
    "                print(repr(longest))\n",
    "\n",
    "                img_name = file.replace('txt', 'jpg')\n",
    "                img_path = path_to_images + img_name\n",
    "                df_row = {'Img_name': img_name, 'Caption':longest, 'Img_path':img_path}\n",
    "                df = df.append(df_row, ignore_index=True)\n",
    "\n",
    "\n",
    "    return df\n",
    "        \n",
    "df = parse_captions(nr_images=20)\n",
    "# df.to_csv(r'C:\\Users\\Rafa\\Downloads\\text\\celeb_preprocessed.csv', sep='\\t')\n",
    "df.to_csv(main  _path + '/celeb_preprocessed_test.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the sketches\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "directory = r\"C:\\Users\\Rafa\\Downloads\\sketchai\\imgs\"\n",
    "os.chdir(r'C:\\Users\\Rafa\\Downloads\\sketchai\\imgs')\n",
    "\n",
    "# sketches\n",
    "for i in range(10000):\n",
    "    # sketches\n",
    "\n",
    "#     img_name = \"fakeA_0_\" + str(i) + \".jpg\"\n",
    "#     img_w_path = directory + \"\\\\\" + img_name\n",
    "#     new_name = str(i) + \".jpg\"\n",
    "#     os.rename(img_name, new_name)\n",
    "\n",
    "    # pics\n",
    "    \n",
    "    img_name = \"inputA_0_\" + str(i) + \".jpg\"\n",
    "    img_w_path = directory + \"\\\\\" + img_name\n",
    "    new_name = r'C:\\Users\\Rafa\\Downloads\\sketchai\\pics' + '\\\\' + str(i) + \".jpg\"\n",
    "    shutil.move(img_w_path, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the generated sketches match the original ones in the data set \n",
    "\n",
    "import os\n",
    "import json \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def fiter_out_stop_words(sentence):\n",
    "    tokenized_sent = word_tokenize(sentence)\n",
    "    tokenized_sent = [word.lower().strip() for word in tokenized_sent if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('English'))\n",
    "    filtered_caption = [word for word in tokenized_sent if word not in stop_words]\n",
    "    return filtered_caption\n",
    "                     \n",
    "#''' Without filtering out the stop words '''\n",
    "# for i in predictions_dict.keys():\n",
    "#     # dropping <start> and <end> tags and turning the caption list into a string\n",
    "#     predicted_caption = (' ').join(predictions_dict[i][1:-1])\n",
    "    \n",
    "#     # loading the original captions\n",
    "#     filename = captions_dir + '\\\\' + i + '.txt'\n",
    "#     with open(filename, 'r', encoding='utf-8') as f:\n",
    "#         real_captions = f.readlines()\n",
    "#     # matching the predicted captions\n",
    "#     real_captions = [caption.lower().strip().replace('.', '').replace(',','') for caption in real_captions]\n",
    "    \n",
    "#     if predicted_caption in real_captions:\n",
    "#         print(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating\n",
      "2 0\n",
      "['person', 'pale', 'skin', 'big', 'nose']\n",
      "['young', 'woman', 'pointy', 'nose', 'big', 'lips']\n"
     ]
    }
   ],
   "source": [
    "predictions_path = open(main_path + '/predictions/' + predictions_file, 'rb')\n",
    "predictions_dict = json.load(predictions_path)\n",
    "\n",
    "#''' Stop words filtered out '''\n",
    "for i in predictions_dict.keys():\n",
    "    # dropping <start> and <end> tags and turning the caption list into a string\n",
    "    predicted_caption = (' ').join(predictions_dict[i][1:-1])\n",
    "    \n",
    "    # loading the original captions\n",
    "#     real_captions_path = captions_dir + '\\\\' + i + '.txt'\n",
    "    real_captions_path = captions_dir + '/' + i + '.txt'\n",
    "    with open(real_captions_path, 'r', encoding='utf-8') as f:\n",
    "        real_captions = f.readlines()\n",
    "\n",
    "    # pre-processing the predicted captions\n",
    "    real_captions = [caption.lower().strip().replace('.', '').replace(',','') for caption in real_captions]\n",
    "    \n",
    "    # dropping the stop words from PREDICTED\n",
    "    predicted_caption = fiter_out_stop_words(predicted_caption)\n",
    "\n",
    "    # dropping the stop words from PREDICTED\n",
    "    real_captions = [fiter_out_stop_words(caption) for caption in real_captions]\n",
    "\n",
    "    \n",
    "    if predicted_caption in real_captions:\n",
    "        print(i)\n",
    "    \n",
    "    max_matching_words = 0\n",
    "    best_match = None\n",
    "    \n",
    "    for i, r_c in enumerate(real_captions):\n",
    "        matching_words = 0\n",
    "        for word in r_c:\n",
    "            if word in predicted_caption:\n",
    "                matching_words += 1\n",
    "                \n",
    "        if matching_words > max_matching_words:\n",
    "            print('updating')\n",
    "            max_matching_words = matching_words\n",
    "            best_match = i\n",
    "            \n",
    "    print(max_matching_words, best_match)\n",
    "    \n",
    "    print(predicted_caption)\n",
    "    print(real_captions[best_match])\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_caps(predictions_dict, captions_dir):\n",
    "\n",
    "    predicted_captions = list()\n",
    "    real_captions = list()\n",
    "\n",
    "    #''' Stop words filtered out '''\n",
    "    for i in predictions_dict.keys():\n",
    "        # dropping <start> and <end> tags and turning the caption list into a string\n",
    "        predicted_caption = (' ').join(predictions_dict[i][1:-1])\n",
    "\n",
    "        # dropping the stop words from PREDICTED\n",
    "        predicted_caption = fiter_out_stop_words(predicted_caption)\n",
    "        \n",
    "        predicted_captions.append(predicted_caption)\n",
    "\n",
    "        # loading the original captions\n",
    "        # real_captions_path = captions_dir + '\\\\' + i + '.txt'\n",
    "        real_caption_path = captions_dir + '/' + i + '.txt'\n",
    "        with open(real_caption_path, 'r', encoding='utf-8') as f:\n",
    "            real_caption = f.readlines()\n",
    "\n",
    "        # pre-processing the predicted captions\n",
    "        real_caption = [caption.lower().strip().replace('.', '').replace(',','') for caption in real_caption]\n",
    "        # dropping the stop words from PREDICTED\n",
    "        real_caption = [fiter_out_stop_words(caption) for caption in real_caption]\n",
    "        real_captions.append(real_caption)\n",
    "        \n",
    "    return predicted_captions, real_captions\n",
    "    \n",
    "    \n",
    "def reformat_to_bigrams(data):\n",
    "    reformatted_to_bigrams = list()\n",
    "    for sentence in data:\n",
    "        bigrammed = list()\n",
    "        for i, word in enumerate(sentence[:-1]):\n",
    "            bigram = (sentence[i], sentence[i+1])\n",
    "            bigrammed.append(bigram)\n",
    "        reformatted_to_bigrams.append(bigrammed)\n",
    "    return reformatted_to_bigrams\n",
    "\n",
    "\n",
    "def evaluate(predicted, actual):\n",
    "    predicted = reformat_to_bigrams(predicted)\n",
    "    \n",
    "    new_actual = list()\n",
    "    for item in actual:\n",
    "        item = reformat_to_bigrams(item)\n",
    "        new_actual.append(item)\n",
    "    \n",
    "    actual = new_actual\n",
    "    \n",
    "    scores = dict()\n",
    "\n",
    "    for i1, predicted_caption in enumerate(predicted):\n",
    "        \n",
    "        scores[i1] = dict()\n",
    "        \n",
    "        for i2, real_caption in enumerate(actual[i1]):\n",
    "            if predicted_caption == real_caption:\n",
    "                print('Complete match at image', i1, 'caption number', i2)\n",
    "#             else:\n",
    "#                 print('1', predicted_caption)\n",
    "#                 print('2', actual[i1][i2])\n",
    "            tp = 0\n",
    "            for tupler in real_caption:\n",
    "                if tupler in predicted_caption:\n",
    "                    tp += 1\n",
    "            try:\n",
    "                score = tp/len(real_caption)*100\n",
    "            except:\n",
    "                score = 0\n",
    "\n",
    "            scores[i1][i2] = score\n",
    "            \n",
    "    return scores\n",
    "\n",
    "\n",
    "def average_evaluations(scores, actual, maximize=True):\n",
    "    new_scores = list()\n",
    "    for img_id, per_caption_scores in scores.items():\n",
    "        per_caption_scores = per_caption_scores.values()\n",
    "        score_list = list(per_caption_scores)\n",
    "        if maximize:\n",
    "            biggest = max(score_list)\n",
    "            new_scores.append(biggest)\n",
    "        else:\n",
    "            avg = sum(score_list)/10\n",
    "            new_scores.append(avg)\n",
    "    return sum(new_scores)/len(actual)\n",
    "\n",
    "\n",
    "def pipeline(main_path):\n",
    "    predictions_dir = main_path + '/predictions'\n",
    "    for predictions_file in listdir(main_path + '/predictions'):\n",
    "        if predictions_file[-5:] == '.json':\n",
    "            print(predictions_file)\n",
    "            predictions_path = open(predictions_dir + '/' + predictions_file, 'rb')\n",
    "            predictions_dict = json.load(predictions_path)\n",
    "            predicted, actual = get_caps(predictions_dict, captions_dir)\n",
    "            scores = evaluate(predicted, actual)\n",
    "            print('Result:', average_evaluations(scores, actual))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions_freakshow_m3_trained_on_imgs.json\n",
      "Complete match at image 66 caption number 5\n",
      "Complete match at image 226 caption number 3\n",
      "Complete match at image 226 caption number 4\n",
      "Complete match at image 542 caption number 4\n",
      "Complete match at image 660 caption number 6\n",
      "Complete match at image 781 caption number 9\n",
      "Result: 19.743054051641526\n"
     ]
    }
   ],
   "source": [
    "# predicted, actual = get_caps(predictions_file, captions_dir)\n",
    "# scores = evaluate(predicted, actual)\n",
    "# average_evaluations(scores, actual)\n",
    "\n",
    "\n",
    "pipeline(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
